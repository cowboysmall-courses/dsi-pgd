
library(car)



data <- read.csv("./data/0304_fundamentals_of_predictive_modelling/predictive_modelling/Performance\ Index.csv", header = TRUE)
head(data)
#   empid   jpi aptitude   tol technical general
# 1     1 45.52    43.83 55.92     51.82   43.58
# 2     2 40.10    32.71 32.56     51.49   51.03
# 3     3 50.61    56.64 54.84     52.29   52.47
# 4     4 38.97    51.53 59.69     47.48   47.69
# 5     5 41.87    51.35 51.50     47.59   45.77
# 6     6 38.71    39.60 43.63     48.34   42.06



model <- lm(jpi ~ aptitude + tol + technical + general, data = data)
summary(model)
# Call:
# lm(formula = jpi ~ aptitude + tol + technical + general, data = data)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -7.2891 -2.7692  0.4562  2.8508  5.6068 
# 
# Coefficients:
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept) -54.28225    7.39453  -7.341 5.41e-08 ***
# aptitude      0.32356    0.06778   4.774 5.15e-05 ***
# tol           0.03337    0.07124   0.468   0.6431    
# technical     1.09547    0.18138   6.039 1.65e-06 ***
# general       0.53683    0.15840   3.389   0.0021 ** 
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 3.549 on 28 degrees of freedom
# Multiple R-squared:  0.8768,	Adjusted R-squared:  0.8592 
# F-statistic: 49.81 on 4 and 28 DF,  p-value: 2.467e-12



influ <- influence.measures(model)
influ
# Influence measures of
#          lm(formula = jpi ~ aptitude + tol + technical + general, data = data) :
#   
#      dfb.1_  dfb.aptt   dfb.tol  dfb.tchn dfb.gnrl   dffit cov.r   cook.d    hat inf
# 1   0.12274 -1.49e-01  0.129300  1.11e-01 -0.23193  0.3688 1.088 2.71e-02 0.1056    
# 2  -0.06975  1.17e-01  0.133588  2.98e-02 -0.09549 -0.2299 1.653 1.09e-02 0.2914   *
# 3   0.00730 -8.66e-03  0.004774  1.49e-02 -0.02638 -0.0473 1.255 4.63e-04 0.0515    
# 4  -0.15696  9.47e-02 -0.173853  2.14e-01 -0.08110 -0.3002 1.152 1.82e-02 0.1009    
# 5   0.05386 -1.09e-02  0.008672 -4.09e-02  0.00366  0.0778 1.248 1.25e-03 0.0564    
# 6   0.24456 -1.68e-01 -0.058830  6.42e-03 -0.12035  0.3513 1.153 2.48e-02 0.1190    
# 7  -0.02188 -1.73e-02  0.012271  6.43e-03  0.01387 -0.0382 1.633 3.02e-04 0.2660   *
# 8  -0.16820  1.32e-02  0.047431  1.75e-01 -0.06910  0.2772 1.124 1.55e-02 0.0839    
# 9  -0.00894  7.48e-04  0.010029 -1.28e-02  0.02059  0.0354 1.283 2.60e-04 0.0682    
# 10  0.11205 -2.25e-01  0.240141 -1.75e-01  0.07832 -0.3408 1.230 2.35e-02 0.1420    
# 11 -0.18055  7.95e-02  0.074018  1.21e-01 -0.05749 -0.2328 1.261 1.11e-02 0.1175    
# 12 -0.34053  3.23e-01 -0.062977  1.49e-01  0.04455  0.4753 1.048 4.44e-02 0.1294    
# 13 -0.00279  1.52e-01  0.050720 -2.02e-02 -0.06082  0.2144 1.411 9.46e-03 0.1819    
# 14  0.03535 -2.71e-02  0.033243  1.67e-02 -0.05554  0.0779 1.503 1.26e-03 0.2052    
# 15 -0.06100  1.62e-05 -0.079422 -3.44e-02  0.14787  0.2052 1.256 8.62e-03 0.1057    
# 16 -0.02601 -5.63e-02  0.145740 -1.91e-01  0.22252  0.3179 1.246 2.05e-02 0.1406    
# 17  0.00576  5.23e-02 -0.223037 -4.56e-02  0.14885  0.3033 1.186 1.86e-02 0.1132    
# 18 -0.47081  7.16e-01 -0.106108 -1.02e-01  0.32416  0.9688 0.836 1.73e-01 0.2138    
# 19 -0.00256 -4.07e-03  0.008451  5.08e-03 -0.00541  0.0141 1.324 4.13e-05 0.0941    
# 20 -0.05213 -1.83e-01  0.123094  7.18e-05  0.05859 -0.2879 1.101 1.66e-02 0.0813    
# 21 -0.09759  1.08e-01 -0.099660  7.75e-02 -0.00599 -0.1526 1.566 4.82e-03 0.2444   *
# 22 -0.03118 -9.58e-03  0.000704  3.82e-02 -0.01003  0.0584 1.320 7.06e-04 0.0968    
# 23  0.22180  1.36e-01 -0.280823  7.63e-02 -0.20983  0.4784 1.109 4.52e-02 0.1477    
# 24 -0.12535 -9.17e-02  0.065917  1.11e-01  0.00703  0.2724 1.140 1.50e-02 0.0871    
# 25  0.17887 -1.87e-01  0.343840 -1.79e-02 -0.21765  0.4657 1.219 4.34e-02 0.1789    
# 26  0.27604  5.50e-02 -0.216138 -2.64e-01  0.11347 -0.5454 0.738 5.50e-02 0.0833    
# 27  0.00964  2.30e-01  0.416005 -2.08e-01 -0.08475 -0.6301 1.454 7.96e-02 0.3020    
# 28  0.09461  3.63e-03 -0.098707  2.63e-01 -0.37691 -0.4574 1.281 4.21e-02 0.1978    
# 29 -0.10548  3.05e-01 -0.745036  7.99e-01 -0.67866 -1.1678 0.565 2.33e-01 0.1918    
# 30  0.03391  1.38e-02  0.036990 -2.56e-02 -0.01450  0.1547 1.102 4.84e-03 0.0352    
# 31  0.00542 -8.51e-03 -0.008686 -3.79e-03  0.00856  0.0193 1.311 7.69e-05 0.0858    
# 32 -0.22236 -1.08e+00  0.359418 -2.29e-01  0.76941 -1.4490 0.523 3.49e-01 0.2395   *
# 33  1.01390 -2.61e-01 -0.059486 -1.31e+00  0.74710 -1.4566 1.340 4.00e-01 0.4421   *


influencePlot(model, id.method = "identify", main = "Influence Plot", sub = "Circle size is proportioal to Cook's Distance")
